{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Lb-WCu3yFkor"
      },
      "source": [
        "這份 Notebook 示範 Google Gemini API 的使用\n",
        "\n",
        "### Google Colab Tips\n",
        "\n",
        "* 用 Shift+Enter 可以執行程式區塊 (或是滑鼠點前面的執行符號)\n",
        "* 如果要修改存檔，需要先點 \"檔案\" -> \"在雲端硬碟中儲存副本\"，複製到你自己的目錄下，才可以儲存\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "fJRzMmqsFkor"
      },
      "source": [
        "## 設定 Google Gemini API Key 變數\n",
        "\n",
        "請點開左側欄的Key符號，就可以設定 Secret。請設定 gemini_api_key\n",
        "\n",
        "請到 https://aistudio.google.com/app/apikey 申請 Gemini API Key\n",
        "\n",
        "* 免費方案有一定的使用限制，但對於學習來說已經足夠\n",
        "* API Key 請妥善保管，不要公開分享\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A7EYg4HJFkos"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('gemini_api_key')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kHcopihkFkos"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from pprint import pp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5WBIJAFkos",
        "outputId": "c320f5f8-fc2f-40fc-db9f-2f58b361965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'candidates': [{'content': {'parts': [{'text': '你好！謝謝你的關心。\\n'\n",
            "                                                '\\n'\n",
            "                                                '作為一個AI，我沒有人類的感受或生活，所以沒有「過得如何」的問題。不過，我的系統運作一切正常，隨時準備好為你提供幫助。\\n'\n",
            "                                                '\\n'\n",
            "                                                '你最近過得如何呢？有什麼我可以為你服務的嗎？'}],\n",
            "                             'role': 'model'},\n",
            "                 'finishReason': 'STOP',\n",
            "                 'index': 0}],\n",
            " 'usageMetadata': {'promptTokenCount': 7,\n",
            "                   'candidatesTokenCount': 64,\n",
            "                   'totalTokenCount': 1156,\n",
            "                   'promptTokensDetails': [{'modality': 'TEXT',\n",
            "                                            'tokenCount': 7}],\n",
            "                   'thoughtsTokenCount': 1085},\n",
            " 'modelVersion': 'models/gemini-2.5-flash-preview-05-20',\n",
            " 'responseId': '-TRSaKiXB5LbjMcPo9-4qAY'}\n"
          ]
        }
      ],
      "source": [
        "# 使用 HTTP 請求直接呼叫 Gemini API\n",
        "payload = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"text\": \"你好，最近過得如何?\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"generationConfig\": {\n",
        "        \"temperature\": 0  # 可以改改看 溫度\n",
        "    }\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Gemini API endpoint\n",
        "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={gemini_api_key}\"\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "obj = json.loads(response.text)\n",
        "\n",
        "pp(obj)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "s-3DG6G4Fkot"
      },
      "source": [
        "## 使用 Google AI Python SDK\n",
        "\n",
        "https://github.com/google/generative-ai-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tttOeDhPFkot",
        "outputId": "70aa5731-5b09-42fb-e41e-bf350aa6cf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.20.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0l-mVhXFkot",
        "outputId": "0dc5f935-4bd8-450f-cee4-fe85eb06fbb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好！謝謝您的關心。\n",
            "\n",
            "我作為一個AI，沒有個人感受或生活體驗，所以沒有「過得如何」的問題，但我一直都運行良好，隨時準備好為您提供幫助！\n",
            "\n",
            "您最近過得怎麼樣呢？有什麼我可以為您服務的嗎？或者有什麼想聊的？\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "# 設定 API Key\n",
        "client = genai.Client(api_key=gemini_api_key)\n",
        "\n",
        "# 生成回應\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"你好，最近過得如何?\",\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "2Wqu1Zy4Fkou"
      },
      "source": [
        "## 使用 System Instruction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60d27hXOFkou",
        "outputId": "40f5dad9-7f11-4865-97da-fa19459d5b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "情緒: **positive**\n",
            "\n",
            "**解釋:**\n",
            "*   \"太好吃\" (tài hǎochī) 是非常正面的形容詞，表示食物味道極佳。\n",
            "*   \"實在\" (shízài) 和 \"太\" (tài) 都起到了加強語氣的作用，使得「好吃」的程度更高。\n",
            "*   語氣助詞 \"啦\" (la) 則表達了說話者的愉悅和肯定。\n",
            "\n",
            "綜合來看，這句話表達了對披薩強烈的喜愛和讚美之情。\n"
          ]
        }
      ],
      "source": [
        "# 這是 completion 風格(蠻多教材仍這樣寫)\n",
        "user_message = \"\"\"請分類以下文字是 neutral, negative 或 positive\n",
        "文字: 我覺得這個披薩實在太好吃啦\n",
        "情緒:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=user_message,\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGbv2jgrFkou",
        "outputId": "d12d62e5-bcb3-4573-9885-a5db49489ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "這段文字是 **positive**。\n",
            "\n",
            "理由：「太好吃啦」明確表達了對披薩的喜愛和讚美，是一種正面的情緒和評價。\n"
          ]
        }
      ],
      "source": [
        "# 可改成使用 system instruction 的風格: 把不變的整體指示放在 system instruction\n",
        "# user prompt 放變動的用戶輸入\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "user_message = \"\"\"\n",
        "文字: 我覺得這個披薩實在太好吃啦\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=user_message,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"請分類以下文字是 neutral, negative 或 positive\"\n",
        "    )\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "WxpSj_vFFkou"
      },
      "source": [
        "## 連續對話多輪對話的場景示範\n",
        "\n",
        "* 模型是 Stateless 無狀態的\n",
        "* 每次你都得把所有對話歷史傳給 Gemini API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAH-AA3bFkou",
        "outputId": "146677df-e5d8-4131-cbb9-438a2f68726b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一輪回答: 2013年的世界棒球經典賽冠軍是**多明尼加共和國**。\n",
            "\n",
            "他們在決賽中以3比0擊敗了波多黎各，並在整個賽事中保持不敗，以完美的戰績奪冠。\n"
          ]
        }
      ],
      "source": [
        "# 使用 Chat Session 進行連續對話\n",
        "from google.genai import types\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model='gemini-2.5-flash',\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a helpful assistant.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# 第一輪問答\n",
        "response1 = chat.send_message(\"誰贏得2013年的世界棒球經典賽冠軍?\")\n",
        "print(\"第一輪回答:\", response1.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssgPzK6hFkov",
        "outputId": "17e6528f-5962-47ad-a48c-31ae7d7811d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第二輪回答: 2017年的世界棒球經典賽冠軍是**美國**。\n",
            "\n",
            "他們在決賽中以8比0擊敗了波多黎各，這也是美國隊首次贏得世界棒球經典賽的冠軍。\n"
          ]
        }
      ],
      "source": [
        "# 延續同一個對話的 第二輪問答\n",
        "response2 = chat.send_message(\"那2017年呢?\")\n",
        "print(\"第二輪回答:\", response2.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdQ8-0U3Fkov",
        "outputId": "e765abe7-0f5f-415b-c630-5d96298e12d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第三輪回答: 美國隊贏過**一次**世界棒球經典賽冠軍。\n",
            "\n",
            "他們是在**2017年**贏得冠軍的。\n"
          ]
        }
      ],
      "source": [
        "# 延續同一個對話的 第三輪問答\n",
        "response3 = chat.send_message(\"美國隊贏過幾次冠軍?\")\n",
        "print(\"第三輪回答:\", response3.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "QQ7KjNanFkov"
      },
      "source": [
        "### 模型的幻覺現象 Hallucination\n",
        "\n",
        "比較聰明的模型，幻覺現象會比較少\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ_IcproFkov",
        "outputId": "a2e66469-f859-44ff-e725-a7ea649e69ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018年回答: 2018年並沒有舉辦世界棒球經典賽。\n",
            "\n",
            "世界棒球經典賽通常是每四年舉辦一次。在2013年之後，下一屆經典賽是在**2017年**舉辦的。\n",
            "\n",
            "**2017年世界棒球經典賽的冠軍是美國隊**，他們在決賽中擊敗了波多黎各。\n"
          ]
        }
      ],
      "source": [
        "# 如果 第二輪問答時 是問 2018 年\n",
        "chat_new = client.chats.create(\n",
        "    model='gemini-2.5-flash',\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a helpful assistant.\"\n",
        "    )\n",
        ")\n",
        "chat_new.send_message(\"誰贏得2013年的世界棒球經典賽冠軍?\")\n",
        "response4 = chat_new.send_message(\"那2018年呢?\")\n",
        "print(\"2018年回答:\", response4.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUv9rRdXFkov",
        "outputId": "2e600496-bbb9-41d8-d029-2d8d28661cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "改善後的2018年回答: 2018年沒有舉辦世界棒球經典賽。\n",
            "\n",
            "世界棒球經典賽通常是四年舉辦一次。在2017年舉辦之後，下一次是在2023年（原定2021年，因疫情延期）。\n"
          ]
        }
      ],
      "source": [
        "# 換一種問法 減少幻覺現象\n",
        "chat_better = client.chats.create(\n",
        "    model='gemini-2.5-flash',\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a helpful assistant.\"\n",
        "    )\n",
        ")\n",
        "chat_better.send_message(\"誰贏得2013年的世界棒球經典賽冠軍?\")\n",
        "response5 = chat_better.send_message(\"那2018年呢? 如果沒舉辦，請回答沒舉辦\")\n",
        "print(\"改善後的2018年回答:\", response5.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "8mxSVkVQFkov"
      },
      "source": [
        "## Few-shot prompting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r4edtQ5Fkov",
        "outputId": "506ec140-6a57-422d-d3a0-9f7916f58b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "# 出處: https://www.promptingguide.ai/zh/techniques/fewshot\n",
        "prompt = f\"\"\"\n",
        "請判斷情緒:\n",
        "\n",
        "input: 這太棒了！\n",
        "output: Positive\n",
        "\n",
        "input: 這太糟糕了！\n",
        "output: Negative\n",
        "\n",
        "input: 哇，那部電影太棒了！\n",
        "output: Positive\n",
        "\n",
        "input: 多麼可怕的節目\n",
        "output:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edw7_SVZFkov",
        "outputId": "f4494b7d-ccfb-4f12-8200-e2cd5d22f223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "這裡提供幾個版本的晶晶體：\n",
            "\n",
            "**版本一 (最經典、最符合定義的):**\n",
            "每位 **employee** 都要 **join** 每週的 **call**，沒有 **exception**。\n",
            "\n",
            "**版本二 (替換更多詞彙):**\n",
            "所有的 **staff** 都 **need to attend** 每週的 **meeting**，**no exception**。\n",
            "\n",
            "**版本三 (更強調「必要」):**\n",
            "每個 **employee** 都 **must** 參加每週的 **phone call**，**definitely no exception**。\n"
          ]
        }
      ],
      "source": [
        "# *在一些較難描述明確指示的任務中，蠻適合用* few-shot 的方式讓模型自己學，例如文字風格、特定的輸出結構(某種schema)\n",
        "\n",
        "# 沒給範例\n",
        "prompt = f\"\"\"\n",
        "晶晶體是一種流行於臺灣以中文為基底，夾雜英語不成句的單字或片語的表達方式。特指所使用的英文字多為過於簡單、沒有替換必要者，進而產生有意炫耀雙語能力卻弄巧成拙的效果。\n",
        "\n",
        "原文: 每位員工都要參加每週電話會議，沒有例外\n",
        "晶晶體:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKnEmc9NFkow",
        "outputId": "e20ef431-d824-40ac-e3d0-8d5d279b7caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "晶晶體: 每位**employee**都要**attend weekly**的**call**，沒有**exception**。\n"
          ]
        }
      ],
      "source": [
        "# 給範例讓模型學風格，可以學得更好\n",
        "prompt = f\"\"\"\n",
        "晶晶體是一種流行於臺灣以中文為基底，夾雜英語不成句的單字或片語的表達方式。特指所使用的英文字多為過於簡單、沒有替換必要者，進而產生有意炫耀雙語能力卻弄巧成拙的效果。\n",
        "例如:\n",
        "\n",
        "原文: 我很忙，因為我很有事要做\n",
        "晶晶體: 我是很busy，因為我很多things要do\n",
        "\n",
        "原文: 天氣總算放晴，沒有下雨、太陽很大、有點熱、讓我想到以前還是學生時，喜歡在這樣的天氣，吃一球冰淇淋，真的會讓人很高興\n",
        "晶晶體: 天氣總算放晴，沒有rain、太陽很big、有點hot、讓我想到以前還是student時，喜歡在這樣的天氣，吃一球ice cream，真的會讓人很happy\n",
        "\n",
        "原文: 每位員工都要參加每週電話會議，沒有例外\n",
        "晶晶體:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "sf0uBcORFkow"
      },
      "source": [
        "## Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "* 給模型思考時間\n",
        "* 示範如何拆解步驟，好讓模型對一個問題進行更長的思考時間 (也就是，有更多的輸出)\n",
        "\n",
        "出處 CoT Paper: https://arxiv.org/abs/2201.11903\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRQBFFCBFkow",
        "outputId": "5375dd7c-b5c0-4550-cf5b-44ea2d1fed59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我們來一步步計算一下：\n",
            "\n",
            "1.  你最初有：10個蘋果\n",
            "2.  給了鄰居2個：10 - 2 = 8個\n",
            "3.  又給了修理工2個：8 - 2 = 6個\n",
            "4.  後來又買了5個：6 + 5 = 11個\n",
            "5.  最後吃了1個：11 - 1 = 10個\n",
            "\n",
            "所以，你還剩下 **10** 個蘋果。\n"
          ]
        }
      ],
      "source": [
        "# 出處: https://promptingguide.azurewebsites.net/techniques/cot\n",
        "prompt = \"\"\"\n",
        "我去市場買了10個蘋果。我給了鄰居2個蘋果，又給修理工2個蘋果。之後，我又去買了5個蘋果，然後吃了1個。我還剩下多少個蘋果？\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu3OkzaNFkow",
        "outputId": "1b1cc25c-acfa-4f59-c457-b764b1d82c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.  **最初購買的數量：** 我一開始有10個蘋果。\n",
            "2.  **給了鄰居後：** 給了鄰居2個，剩下 10 - 2 = 8 個蘋果。\n",
            "3.  **再給了修理工後：** 又給了修理工2個，剩下 8 - 2 = 6 個蘋果。\n",
            "4.  **再次購買後：** 又去買了5個，所以現在有 6 + 5 = 11 個蘋果。\n",
            "5.  **吃了一個後：** 吃了1個，所以剩下 11 - 1 = 10 個蘋果。\n",
            "6.  **最後剩下10個蘋果。**\n"
          ]
        }
      ],
      "source": [
        "# Few-shot CoT - 給一個推理範例，也就是 Chain of Thought (CoT) 思考過程\n",
        "prompt = \"\"\"\n",
        "Q: 我去市場買了6個香蕉，給了朋友3個香蕉，我還剩下多少個?\n",
        "A:\n",
        "  1. 我一開始有6個\n",
        "  2. 給了朋友3個，所以剩下 6-3=3個香蕉\n",
        "  3. 最後剩下3個香蕉\n",
        "\n",
        "Q: 我去市場買了10個蘋果。我給了鄰居2個蘋果，又給修理工2個蘋果。之後，我又去買了5個蘋果，然後吃了1個。我還剩下多少個蘋果？\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vove-oZFkow",
        "outputId": "0cf4d69c-ab7c-4d79-e91b-7f157a0e82c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "好的，我們一步一步來計算：\n",
            "\n",
            "1.  **一開始買了**：10個蘋果\n",
            "2.  **給了鄰居**：10 - 2 = 8個蘋果\n",
            "3.  **又給了修理工**：8 - 2 = 6個蘋果\n",
            "4.  **後來又買了**：6 + 5 = 11個蘋果\n",
            "5.  **吃掉了**：11 - 1 = 10個蘋果\n",
            "\n",
            "你還剩下 **10** 個蘋果。\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot CoT (讓模型自己想步驟)\n",
        "# 標準咒語是 Let's think step by step\n",
        "prompt = \"\"\"\n",
        "我去市場買了10個蘋果。我給了鄰居2個蘋果，又給修理工2個蘋果。之後，我又去買了5個蘋果，然後吃了1個。我還剩下多少個蘋果？\n",
        "Let's think step by step\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "FjJzH90OFkow"
      },
      "source": [
        "## 如何做 結構化輸出 (JSON 輸出) ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDEQg-LmFkow",
        "outputId": "f598f718-ec11-41eb-d87a-52e54acbe719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "好的，這是隨機產生三筆 user 資料的 JSON 格式：\n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"id\": \"usr-001\",\n",
            "    \"username\": \"john_doe\",\n",
            "    \"email\": \"john.doe@example.com\",\n",
            "    \"age\": 30,\n",
            "    \"isActive\": true,\n",
            "    \"\"registeredDate\": \"2023-01-15T10:30:00Z\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"usr-002\",\n",
            "    \"username\": \"jane_smith\",\n",
            "    \"email\": \"jane.smith@example.com\",\n",
            "    \"age\": 24,\n",
            "    \"isActive\": true,\n",
            "    \"registeredDate\": \"2022-07-20T14:00:00Z\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"usr-003\",\n",
            "    \"username\": \"peter_chen\",\n",
            "    \"email\": \"peter.chen@example.com\",\n",
            "    \"age\": 45,\n",
            "    \"isActive\": false,\n",
            "    \"registeredDate\": \"2021-03-01T08:45:00Z\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt = \"請隨機產生三個 user 資料，請用 JSON 格式回傳\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqbL9n6nFkow",
        "outputId": "5f2f6376-106a-481b-b9e1-9890ef16553c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"陳淑芬\",\n",
            "  \"age\": 32,\n",
            "  \"bio\": \"來自台北的軟體工程師，熱愛爬山和攝影，喜歡探索台灣的自然美景。\",\n",
            "  \"avatar_url\": \"https://picsum.photos/id/1012/200/300\",\n",
            "  \"isSubscriber\": true\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Gemini 的 Structured Output 功能\n",
        "# 文件: https://ai.google.dev/gemini-api/docs/json-mode\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "# 定義 JSON Schema\n",
        "response_schema = {\n",
        "    \"type\": \"OBJECT\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\n",
        "            \"type\": \"STRING\",\n",
        "            \"description\": \"請用台灣常見姓名\"\n",
        "        },\n",
        "        \"age\": {\n",
        "            \"type\": \"INTEGER\",\n",
        "            \"description\": \"年紀\"\n",
        "        },\n",
        "        \"bio\": {\n",
        "            \"type\": \"STRING\",\n",
        "            \"description\": \"請用台灣繁體中文\"\n",
        "        },\n",
        "        \"avatar_url\": {\n",
        "            \"type\": \"STRING\",\n",
        "            \"description\": \"個人圖像，請用真實可以連結的圖片\"\n",
        "        },\n",
        "        \"isSubscriber\": {\n",
        "            \"type\": \"BOOLEAN\",\n",
        "            \"description\": \"是否訂閱\"\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\n",
        "        \"name\",\n",
        "        \"age\",\n",
        "        \"bio\",\n",
        "        \"avatar_url\",\n",
        "        \"isSubscriber\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 使用 response schema\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema\n",
        "    )\n",
        ")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw-sUgGnFkox",
        "outputId": "a665cf2f-dc19-42ad-e1fc-dcb6eea30028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Schema: {'$defs': {'User': {'properties': {'name': {'description': '請用台灣常見姓名', 'title': 'Name', 'type': 'string'}, 'age': {'description': '年紀', 'title': 'Age', 'type': 'integer'}, 'bio': {'description': '請用台灣繁體中文', 'title': 'Bio', 'type': 'string'}, 'avatar_url': {'description': '個人圖像，請用真實可以連結的圖片', 'title': 'Avatar Url', 'type': 'string'}, 'isSubscriber': {'description': '是否訂閱', 'title': 'Issubscriber', 'type': 'boolean'}}, 'required': ['name', 'age', 'bio', 'avatar_url', 'isSubscriber'], 'title': 'User', 'type': 'object'}}, 'properties': {'users': {'items': {'$ref': '#/$defs/User'}, 'title': 'Users', 'type': 'array'}}, 'required': ['users'], 'title': 'Users', 'type': 'object'}\n"
          ]
        }
      ],
      "source": [
        "# 使用 Pydantic 定義 schema 更方便\n",
        "from typing import List\n",
        "from pydantic import Field, BaseModel, ConfigDict\n",
        "\n",
        "class User(BaseModel):\n",
        "    name: str = Field(description=\"請用台灣常見姓名\")\n",
        "    age: int = Field(description=\"年紀\")\n",
        "    bio: str = Field(description=\"請用台灣繁體中文\")\n",
        "    avatar_url: str = Field(description=\"個人圖像，請用真實可以連結的圖片\")\n",
        "    isSubscriber: bool = Field(description=\"是否訂閱\")\n",
        "\n",
        "class Users(BaseModel):\n",
        "    users: list[User]\n",
        "\n",
        "# 將 Pydantic model 轉換為 Gemini 可用的 schema\n",
        "def pydantic_to_gemini_schema(pydantic_model):\n",
        "    schema = pydantic_model.model_json_schema()\n",
        "    return schema\n",
        "\n",
        "users_schema = pydantic_to_gemini_schema(Users)\n",
        "print(\"Generated Schema:\", users_schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcXTG1uBFkox",
        "outputId": "f90a59b2-aaf4-48b0-de6a-d6296798c7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"users\": [{\"name\": \"陳美玲\", \"age\": 28, \"bio\": \"我是美玲，喜歡閱讀和手作烘焙。假日經常在咖啡廳度過，享受一杯好咖啡的時光。\", \"avatar_url\": \"https://i.imgur.com/8Q9K2mH.jpeg\", \"isSubscriber\": true}, {\"name\": \"林志明\", \"age\": 35, \"bio\": \"我叫志明，是個程式設計師，熱愛學習新技術。下班後喜歡打籃球或爬山，保持身心健康。\", \"avatar_url\": \"https://i.imgur.com/G4Y2B7K.jpeg\", \"isSubscriber\": false}, {\"name\": \"王雅婷\", \"age\": 22, \"bio\": \"大家好，我是雅婷。目前是一名大學生，主修設計。平常喜歡畫畫和聽音樂，夢想是成為一名插畫家。\", \"avatar_url\": \"https://i.imgur.com/5J3K7pM.jpeg\", \"isSubscriber\": true}]}\n",
            "\n",
            "解析後的第一個用戶: name='陳美玲' age=28 bio='我是美玲，喜歡閱讀和手作烘焙。假日經常在咖啡廳度過，享受一杯好咖啡的時光。' avatar_url='https://i.imgur.com/8Q9K2mH.jpeg' isSubscriber=True\n"
          ]
        }
      ],
      "source": [
        "# 使用 Pydantic schema 創建請求\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=\"請隨機產生多個 user 資料\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=users_schema\n",
        "    )\n",
        ")\n",
        "print(response.text)\n",
        "\n",
        "# 解析回應到 Pydantic 物件\n",
        "import json\n",
        "response_data = json.loads(response.text)\n",
        "parsed_users = Users(**response_data)\n",
        "print(\"\\n解析後的第一個用戶:\", parsed_users.users[0])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "cyerqVKkFkox"
      },
      "source": [
        "## Prompt Chaining: 工具串接\n",
        "\n",
        "三個步驟:\n",
        "\n",
        "1. 從用戶問題中，用 prompt1 來提取出 外部工具的參數\n",
        "2. 執行外部工具，拿到結果\n",
        "3. 用 (prompt2 + 結果) 轉成自然語言回給用戶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nslGAc-GFkox",
        "outputId": "670e232d-c5e6-4cf3-ddfc-a83218fa0af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "提取的參數: date='20250618' stock_code='2330'\n"
          ]
        }
      ],
      "source": [
        "# Step 1: 從用戶問題中，用 prompt1 來提取出 外部工具的參數\n",
        "from typing import List\n",
        "from pydantic import Field, BaseModel\n",
        "\n",
        "class QueryResult(BaseModel):\n",
        "    date: str = Field(description=\"Date in yyyymmdd format. Leave empty if not parsable\")\n",
        "    stock_code: str = Field(description=\"Taiwan stock code as a 4-digit number. Leave empty if not parsable\")\n",
        "\n",
        "query = \"請問2025年6月18號的「台積電」，股價表現如何?\"\n",
        "\n",
        "# 使用參數提取\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=query,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"Extract from user queries\",\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=pydantic_to_gemini_schema(QueryResult)\n",
        "    )\n",
        ")\n",
        "\n",
        "extracted_data = json.loads(response.text)\n",
        "parsed_result = QueryResult(**extracted_data)\n",
        "print(\"提取的參數:\", parsed_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcCaZRRwFkox",
        "outputId": "15bd804b-f535-4198-d02e-3a1a20dadbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "取得的股價資料: {'stat': 'OK', 'date': '20250618', 'title': '114年06月 2330 台積電           各日成交資訊', 'fields': ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數'], 'data': [['114/06/02', '40,608,468', '38,643,155,297', '958.00', '961.00', '946.00', '946.00', '-21.00', '125,245'], ['114/06/03', '27,482,916', '26,302,041,072', '960.00', '965.00', '950.00', '950.00', '+4.00', '43,550'], ['114/06/04', '43,196,396', '42,419,360,833', '974.00', '990.00', '970.00', '990.00', '+40.00', '73,539'], ['114/06/05', '27,047,750', '26,936,792,104', '1,000.00', '1,000.00', '991.00', '998.00', '+8.00', '51,309'], ['114/06/06', '18,797,346', '18,688,985,614', '997.00', '997.00', '991.00', '995.00', '-3.00', '27,283'], ['114/06/09', '23,952,041', '24,100,014,375', '1,005.00', '1,010.00', '1,000.00', '1,005.00', '+10.00', '56,903'], ['114/06/10', '55,353,908', '57,406,744,645', '1,025.00', '1,050.00', '1,020.00', '1,045.00', '+40.00', '138,656'], ['114/06/11', '46,137,188', '48,960,267,029', '1,065.00', '1,070.00', '1,055.00', '1,065.00', '+20.00', '75,830'], ['114/06/12', '28,661,875', '30,064,888,046', '1,055.00', '1,060.00', '1,045.00', '1,045.00', 'X0.00', '40,293'], ['114/06/13', '31,371,948', '32,434,779,823', '1,040.00', '1,040.00', '1,025.00', '1,030.00', '-15.00', '40,938'], ['114/06/16', '31,257,555', '31,982,385,770', '1,030.00', '1,030.00', '1,015.00', '1,025.00', '-5.00', '38,583'], ['114/06/17', '30,890,431', '32,183,667,155', '1,040.00', '1,050.00', '1,035.00', '1,045.00', '+20.00', '30,757'], ['114/06/18', '39,423,315', '41,289,195,000', '1,040.00', '1,055.00', '1,030.00', '1,055.00', '+10.00', '45,603']], 'notes': ['符號說明:+/-/X表示漲/跌/不比價', '當日統計資訊含一般、零股、盤後定價，不含鉅額、拍賣、標購。', 'ETF證券代號第六碼為K、M、S、C者，表示該ETF以外幣交易。', '權證證券代號可重複使用，權證顯示之名稱係目前存續權證之簡稱。'], 'total': 13}\n"
          ]
        }
      ],
      "source": [
        "# Step 2: 執行工具，拿到結果\n",
        "# API 參考自 https://medium.com/%E5%B7%A5%E7%A8%8B%E9%9A%A8%E5%AF%AB%E7%AD%86%E8%A8%98/5%E7%A8%AE%E6%8A%93%E5%8F%96%E5%8F%B0%E8%82%A1%E6%AD%B7%E5%8F%B2%E8%82%A1%E5%83%B9%E7%9A%84%E6%96%B9%E6%B3%95-766bf2ed9d6\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "date = parsed_result.date\n",
        "stock_code = parsed_result.stock_code\n",
        "url = 'https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=%s&stockNo=%s' % (date, stock_code)\n",
        "\n",
        "html = requests.get(url)\n",
        "context = json.loads(html.text)\n",
        "print(\"取得的股價資料:\", context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "2xBuyCnhFkox",
        "outputId": "b3a5598e-68a9-4270-db39-0ff8bb8c63cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終回答: 根據提供的資料，2025年6月18日（114年06月18日）台積電的股價表現如下：\n",
            "\n",
            "*   **開盤價**：1,040.00元\n",
            "*   **最高價**：1,055.00元\n",
            "*   **最低價**：1,030.00元\n",
            "*   **收盤價**：1,055.00元\n",
            "*   **漲跌價差**：上漲10.00元\n",
            "*   **成交股數**：39,423,315股\n",
            "*   **成交金額**：41,289,195,000元\n",
            "*   **成交筆數**：45,603筆\n"
          ]
        }
      ],
      "source": [
        "# Step 3: 用 (prompt2 + 結果) 轉成自然語言回給用戶\n",
        "prompt = f\"\"\"\n",
        "Based on the provided context, please answer the following question in Traditional Chinese (Taiwan):\n",
        "\n",
        "Question: <question>{query}</question>\n",
        "\n",
        "Context: <context>{context}</context>\n",
        "\n",
        "Instructions:\n",
        "1. Carefully verify that your answer is supported by the given context.\n",
        "2. If the question cannot be answered from the provided context, respond with: \"抱歉，在提供的資料中找不到相關資訊，無法回答您的問題。\"\n",
        "3. Do not include information that is not present in the context.\n",
        "4. Ensure your response is written in Traditional Chinese as used in Taiwan.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(\"最終回答:\", response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 案例: 長文產生器，拆解多個子主題，分開搜尋回答後，最後整合在一起\n",
        "\n",
        "\n",
        "根據用戶輸入的主題生成一篇全面綜述文章，流程是\n",
        "\n",
        "1. 根據用戶輸入的主題，拆解成多個子主題\n",
        "2. 針對每個子主題，進行網路搜尋出參考資料，然後生成獨立的子文章\n",
        "3. 將所有子文章整合並潤飾成一篇連貫的長文。\n",
        "\n",
        "其中步驟 (2) 是平行執行\n",
        "\n",
        "和上一個摘要的 Parallelization 的差異在於，這裏的第一步 Orchestrator 會用 AI 來拆解出不固定的子任務。\n",
        "\n",
        "<img src=\"https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75\">\n"
      ],
      "metadata": {
        "id": "ej-bXECRJ2Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU1Rke4sJ-Co",
        "outputId": "95e9adde-fda1-47cb-b306-1a43223f7b4e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.6-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.14.0)\n",
            "Downloading tavily_python-0.7.6-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.7.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from datetime import datetime\n",
        "from tavily import TavilyClient\n",
        "\n",
        "tavily_client = TavilyClient(api_key= userdata.get('tavily_api_key') )"
      ],
      "metadata": {
        "id": "NY2aeBlEKFQp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "zPBUvgSYFkox"
      },
      "source": [
        "## Function Calling\n",
        "\n",
        "Gemini 的 Function Calling 功能與 OpenAI 相似，但語法略有不同\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5o7zIJFkoy",
        "outputId": "4ccfe443-a0b1-4385-ad7c-5333f88e2f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型回應:\n",
            "None\n",
            "\n",
            "Function Calls:\n",
            "Function: web_search\n",
            "Arguments: {'keyword': '2025/06/18 台北天氣'}\n",
            "Function Result: [{'title': '台北市2025年的天氣歷史 台灣 - tw.weatherspark.com', 'url': 'https://tw.weatherspark.com/h/y/137170/2025/台北市、台灣2025年歷史天氣', 'content': '此報告顯示了台北市的過去天氣，並提供了2025年的天氣歷史。 它突出了我們的所有可用歷史天氣資料系列，包含台北市2025年的溫度歷史。 您可以透過點選圖表，從年份進一步檢視特定月份，甚至特定的一天的報告。 ... 嚴寒-9°c 極冷 0°c 寒冷 7°c 冷 13°c 涼爽 18', 'score': 0.78749067, 'raw_content': None}, {'title': '臺北市, 台北市, 臺灣 每月天氣 | AccuWeather', 'url': 'https://www.accuweather.com/zh/tw/taipei-city/315078/june-weather/315078', 'content': '臺北市, 台北市, 臺灣 每月天氣 | AccuWeather 返回 []( 台北市 ======== 86°F 使用目前位置 最近 臺北市 台北市 86° 未找到結果。 嘗試搜尋城市、郵遞區號或興趣點。 設定 臺北市, 台北市 天氣 今天WinterCast當地{stormName}追蹤每小時每天雷達MinuteCast每月空氣品質健康與活動 全球範圍 ### 颶風### 惡劣天氣### 雷達與氣象圖### 視訊 1 91° 74°2 95° 79°3 85° 74°4 76° 73°5 77° 74°6 無7 94° 77°8 93° 78°9 94° 78°10 97° 80°11 98° 80°12 88° 78°13 85° 77°14 86° 76°15 88° 77°16 88° 78°17 89° 78°18 88° 77°19 86° 80°20 86° 80°21 87° 79°22 86° 78°23 87° 80°24 84° 79°25 86° 79°26 86° 78°27 87° 79°28 88° 80°29 87° 80°30 87° 80°1 88° 80°2 89° 80°3 88° 81°4 88° 81°5 89° 80° °F © 2025 AccuWeather, Inc. 版權所有。「AccuWeather」和太陽商標設計是 AccuWeather, Inc. 的註冊商標。保留所有權利。  Get AccuWeather alerts as they happen with our browser notifications. Enable Notifications Notifications Enabled', 'score': 0.72207695, 'raw_content': None}, {'title': '熱到爆!中南部高溫達36度 專家警告：北台、中南山區易有雷陣雨 | 生活 | Newtalk新聞', 'url': 'https://newtalk.tw/news/view/2025-06-18/976831', 'content': '台灣今（18日）受太平洋高壓增強影響，氣溫持續飆升，尤其中南部內陸及台北盆地高溫恐突破36度，氣象署針對高雄與屏東亮出高溫黃色燈號。天氣', 'score': 0.41620392, 'raw_content': None}, {'title': '對流旺盛午後防大雨 未來一周3地高溫飆36度以上 | ETtoday生活新聞 | ETtoday新聞雲', 'url': 'https://www.ettoday.net/news/20250618/2980539.htm', 'content': '未來一周天氣趨勢。（圖／氣象署） 記者周湘芸／台北報導. 未來一周持續炎熱，大台北地區、花東縱谷及中南部近山區都有36度高溫，隨著風場', 'score': 0.35931972, 'raw_content': None}, {'title': '臺北市, 臺北市每月天氣預報 - weather.com - The Weather Channel', 'url': 'https://weather.com/zh-TW/weather/monthly/l/d357f08735408ecba1ca2cb0961fb423059f506d67b053ae6107c5e508362efa', 'content': 'Weather.com 為您帶來最準確的 臺北市, 臺北市 每月氣象預報平均/記錄和高/低溫、降雨量及更多資訊。', 'score': 0.17904232, 'raw_content': None}]\n",
            "\n",
            "最終回應: 根據 AccuWeather 的資料，2025年6月18日台北的天氣預計會很熱，最高溫約 88°F (約 31.1°C)，最低溫約 77°F (約 25°C)。\n",
            "\n",
            "另外，也有新聞指出當天台北盆地高溫可能突破 36°C，大台北地區也會有 36°C 以上的高溫。請注意防曬與補充水分。\n"
          ]
        }
      ],
      "source": [
        "# Step 1: 定義工具函式\n",
        "def web_search(keyword: str) -> str:\n",
        "    response = tavily_client.search(query=keyword)\n",
        "    return str(response[\"results\"])\n",
        "\n",
        "# Step 2: 定義函數描述給 Gemini\n",
        "web_search_tool = types.Tool(\n",
        "    function_declarations=[\n",
        "        types.FunctionDeclaration(\n",
        "            name=\"web_search\",\n",
        "            description=\"搜尋最新的資訊\",\n",
        "            parameters=types.Schema(\n",
        "                type=types.Type.OBJECT,\n",
        "                properties={\n",
        "                    \"keyword\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"搜尋關鍵字\"\n",
        "                    )\n",
        "                },\n",
        "                required=[\"keyword\"]\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 3: 發送請求 (使用新的 client.models.generate_content)\n",
        "today = datetime.now().strftime(\"%Y/%m/%d\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=f\"今天 {today} 台北的天氣如何？\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        tools=[web_search_tool]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"模型回應:\")\n",
        "print(response.text)\n",
        "\n",
        "print(\"\\nFunction Calls:\")\n",
        "for candidate in response.candidates:\n",
        "    for part in candidate.content.parts:\n",
        "        if hasattr(part, 'function_call') and part.function_call:\n",
        "            print(f\"Function: {part.function_call.name}\")\n",
        "            print(f\"Arguments: {dict(part.function_call.args)}\")\n",
        "\n",
        "            # Step 4: 執行函數調用\n",
        "            if part.function_call.name == \"web_search\":\n",
        "                keyword = part.function_call.args[\"keyword\"]\n",
        "                result = web_search(keyword)\n",
        "                print(f\"Function Result: {result}\")\n",
        "\n",
        "                # Step 5: 將結果回傳給模型\n",
        "                final_response = client.models.generate_content(\n",
        "                    model='gemini-2.5-flash',\n",
        "                    contents=[\n",
        "                        f\"今天 {today} 台北的天氣如何？\",\n",
        "                        types.Content(\n",
        "                            parts=[types.Part(function_call=part.function_call)]\n",
        "                        ),\n",
        "                        types.Content(\n",
        "                            parts=[types.Part(\n",
        "                                function_response=types.FunctionResponse(\n",
        "                                    name=\"web_search\",\n",
        "                                    response={\"result\": result}\n",
        "                                )\n",
        "                            )]\n",
        "                        )\n",
        "                    ]\n",
        "                )\n",
        "                print(f\"\\n最終回應: {final_response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRcN1mNLFkoy"
      },
      "outputs": [],
      "source": [
        "# Step 5: 處理函數調用並執行\n",
        "available_functions = {\n",
        "    \"web_search\": web_search\n",
        "}\n",
        "\n",
        "# 如果有函數調用，執行它們\n",
        "if any(part.function_call for part in response.parts):\n",
        "    # 收集函數調用結果\n",
        "    function_responses = []\n",
        "\n",
        "    for part in response.parts:\n",
        "        if part.function_call:\n",
        "            function_name = part.function_call.name\n",
        "            function_args = dict(part.function_call.args)\n",
        "\n",
        "            print(f\"執行函數: {function_name}({function_args})\")\n",
        "\n",
        "            # 調用實際函數\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_result = function_to_call(**function_args)\n",
        "\n",
        "            print(f\"函數結果: {function_result}\")\n",
        "\n",
        "            # 準備函數回應\n",
        "            function_response = genai.protos.Part(\n",
        "                function_response=genai.protos.FunctionResponse(\n",
        "                    name=function_name,\n",
        "                    response={\"result\": function_result}\n",
        "                )\n",
        "            )\n",
        "            function_responses.append(function_response)\n",
        "\n",
        "    # Step 6: 將函數結果回傳給模型生成最終回應\n",
        "    final_response = model_with_tools.generate_content([\n",
        "        genai.protos.Content(parts=response.parts),  # 原始回應\n",
        "        genai.protos.Content(parts=function_responses)  # 函數結果\n",
        "    ])\n",
        "\n",
        "    print(\"\\n最終回應:\")\n",
        "    print(final_response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQspH2RnFkoy"
      },
      "outputs": [],
      "source": [
        "# 包成一個完整的 function calling 輔助函數\n",
        "def run_gemini_with_functions(model, user_message, available_functions):\n",
        "    \"\"\"執行帶有函數調用的 Gemini 請求\"\"\"\n",
        "\n",
        "    print(f\"💬 用戶問題: {user_message}\")\n",
        "\n",
        "    # 第一次調用\n",
        "    response = model.generate_content(user_message)\n",
        "\n",
        "    # 檢查是否有函數調用\n",
        "    function_calls = [part for part in response.parts if part.function_call]\n",
        "\n",
        "    if function_calls:\n",
        "        print(\"🔧 檢測到函數調用\")\n",
        "\n",
        "        # 執行所有函數調用\n",
        "        function_responses = []\n",
        "\n",
        "        for part in response.parts:\n",
        "            if part.function_call:\n",
        "                function_name = part.function_call.name\n",
        "                function_args = dict(part.function_call.args)\n",
        "\n",
        "                print(f\"   ⚙️ 執行函數 {function_name} 參數 {function_args}\")\n",
        "\n",
        "                # 調用實際函數\n",
        "                function_to_call = available_functions[function_name]\n",
        "                function_result = function_to_call(**function_args)\n",
        "\n",
        "                # 準備函數回應\n",
        "                function_response = genai.protos.Part(\n",
        "                    function_response=genai.protos.FunctionResponse(\n",
        "                        name=function_name,\n",
        "                        response={\"result\": function_result}\n",
        "                    )\n",
        "                )\n",
        "                function_responses.append(function_response)\n",
        "\n",
        "        # 第二次調用，包含函數結果\n",
        "        final_response = model.generate_content([\n",
        "            genai.protos.Content(parts=response.parts),\n",
        "            genai.protos.Content(parts=function_responses)\n",
        "        ])\n",
        "\n",
        "        return final_response.text\n",
        "    else:\n",
        "        # 沒有函數調用，直接返回\n",
        "        return response.text\n",
        "\n",
        "# 測試這個輔助函數\n",
        "result = run_gemini_with_functions(\n",
        "    model_with_tools,\n",
        "    \"今天台北、新竹、高雄的天氣如何？\",\n",
        "    available_functions\n",
        ")\n",
        "\n",
        "print(\"------\")\n",
        "print(\"最終結果:\", result)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "dhtMQ4AkFko2"
      },
      "source": [
        "## Gemini 的多模態能力\n",
        "\n",
        "Gemini 原生支援圖像、音訊、影片等多種輸入格式，這是它相比 OpenAI 的一大優勢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hU2gkz3Fko2"
      },
      "outputs": [],
      "source": [
        "# 圖像處理範例\n",
        "# 首先我們需要上傳一個圖像文件到 Gemini\n",
        "\n",
        "# 方法1: 從 URL 載入圖像 (需要 Pillow)\n",
        "%pip install Pillow\n",
        "\n",
        "import PIL.Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# 下載一個範例圖像\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "response = requests.get(image_url)\n",
        "image = PIL.Image.open(BytesIO(response.content))\n",
        "\n",
        "# 使用 Gemini 分析圖像\n",
        "multimodal_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = multimodal_model.generate_content([\n",
        "    \"請詳細描述這張圖片的內容，包括景觀、顏色、氛圍等。請用繁體中文回答。\",\n",
        "    image\n",
        "])\n",
        "\n",
        "print(\"圖像分析結果:\")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "8mcm1jTbFko2"
      },
      "source": [
        "## 總結\n",
        "\n",
        "這份 Notebook 示範了 Google Gemini API 的主要功能：\n",
        "\n",
        "1. **基本使用** - 直接 HTTP 請求和 Python SDK\n",
        "2. **System Instructions** - 相當於 OpenAI 的 System Message\n",
        "3. **多輪對話** - 使用 ChatSession\n",
        "4. **Prompt 技術** - Few-shot, Chain-of-Thought 等\n",
        "5. **結構化輸出** - JSON Schema 支援\n",
        "6. **Prompt Chaining** - 工具串接\n",
        "7. **Function Calling** - 函數調用功能\n",
        "8. **多模態能力** - 圖像、音訊、影片處理\n",
        "\n",
        "### Gemini vs OpenAI 主要差異\n",
        "\n",
        "**Gemini 優勢:**\n",
        "- 原生多模態支援\n",
        "- 更長的 context window\n",
        "- 免費額度較大方\n",
        "- Google 生態系整合\n",
        "\n",
        "**OpenAI 優勢:**\n",
        "- 生態系更成熟（工具、框架）\n",
        "- API 穩定性較高\n",
        "- 社群資源豐富\n",
        "- 推理能力通常較強\n",
        "\n",
        "選擇哪個平台應該根據您的具體需求、預算和技術要求來決定。\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}